{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69119279",
   "metadata": {},
   "source": [
    "# Twitter API Tutorial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de93501e",
   "metadata": {},
   "source": [
    "Today, we're going to look at how to interact with Twitter's API so that we can easily access some tweets.\n",
    "\n",
    "Recall that API stands for Application Programming Interface, and is a way for some programmes to interact with other programmes. (An interface is a standard way to access some functionality.)\n",
    "\n",
    "We'll use the requests library to make some API requests for past tweets, and Twitter's twitter-stream library to get a real-time stream of tweets.\n",
    "\n",
    "But first: A bit on access tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49acb2c5",
   "metadata": {},
   "source": [
    "## API Access Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57314360",
   "metadata": {},
   "source": [
    "Last week, we were able to use a weather API by going to the appropiate URL endpoint with the right queries. Some services like to restrict access to all or some of their APIs behind access tokens.\n",
    "\n",
    "Firstly, this let's them keep track of who is using which resources, so anyone abusing the services (intentionally or not) can have access cut off. This is called 'rate limiting'.\n",
    "\n",
    "Secondly, it let's them give different levels of access to different people. Advertisers on Twitter, as well as accedemic researchers, can get access to more powerful APIs that the rest of us!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4039a28c",
   "metadata": {},
   "source": [
    "To save time, I'll be giving you all access tokens that I've previously registered. There are about 400,000 tweets left on it for the month, but with a class of 80+ that can go fast, so please **remember to turn off any tweet streams!**\n",
    "\n",
    "If you want to use the Twitter API for any projects/CAs, you'll need your own access tokens. Let me know and I can help you set it up!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26786cbb",
   "metadata": {},
   "source": [
    "## Using API tokens (or other authentication materials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5329c65d",
   "metadata": {},
   "source": [
    "In general, you want to avoid sharing your access tokens.\n",
    "\n",
    "Beware that versioning software like Git and GitHub keeps ALL of your previous committs. So if you leave access tokens in ANY commit, people can go back though the versioning history and find it!\n",
    "\n",
    "Because of this, we are going to save our access tokens as **enviromental variables**.\n",
    "\n",
    "These can then be read by Python into our programme, without having to ever have them explicitly in the code.\n",
    "\n",
    "Another reason to do this is for when you are sharing your code: people can then just run it with their access tokens.\n",
    "\n",
    "We'll be using the python-dotenv library to handle this for us.\n",
    "\n",
    "The access tokens will be saved in a file called .env (hence the library name).\n",
    "\n",
    "These are normally **hidden files** so you may not be able to view it- you'll have to change your view settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acb6b14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\kftsu\\anaconda3\\lib\\site-packages (0.21.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393a1fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "# your Twitter API key and API secret\n",
    "# We won't be using these variables, they're just for demonstration.\n",
    "my_api_key = config[\"API_KEY\"]\n",
    "my_api_key_secret = config[\"API_KEY_SECRET\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede04d32",
   "metadata": {},
   "source": [
    "The twitter-stream library will look for the access tokens in a particular place on your computer. This section is to make the correct file in the appropiate location. You can do this manually either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c8edea",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_keys = f'''keys:\n",
    "    access_token: {config[\"API_KEY\"]}\n",
    "    access_token_secret: {config[\"API_KEY_SECRET\"]}\n",
    "    bearer_token: {config[\"BEARER_TOKEN\"]}\n",
    "'''\n",
    "# Mac might be able to use \"~/.twitter-keys.yaml\"\n",
    "with open(\"C:/Users/sweis/.twitter-keys.yaml\", \"w\") as file:\n",
    "    file.write(twitter_keys)\n",
    "with open(\"C:/Users/sweis/.twitter_keys.yaml\", \"w\") as file:\n",
    "    file.write(twitter_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85edf8a1",
   "metadata": {},
   "source": [
    "Now that that is all done, we can let the fun begin!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a71e14",
   "metadata": {},
   "source": [
    "## Twitter Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016f33bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12312f6a",
   "metadata": {},
   "source": [
    "Source: https://github.com/twitterdev/Twitter-API-v2-sample-code\n",
    "\n",
    "We've using the recent-search functionality:\n",
    "https://github.com/twitterdev/Twitter-API-v2-sample-code/blob/main/Recent-Search/recent_search.py\n",
    "\n",
    "For more on building tweet queries:\n",
    "https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c59354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# As an alternative to the .env file, you can do this:\n",
    "# To set your environment variables in your terminal run the following line:\n",
    "# export 'BEARER_TOKEN'='<your_bearer_token>'\n",
    "bearer_token = config[\"BEARER_TOKEN\"]\n",
    "\n",
    "search_url = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "\n",
    "# Optional params: start_time,end_time,since_id,until_id,max_results,next_token,\n",
    "# expansions,tweet.fields,media.fields,poll.fields,place.fields,user.fields\n",
    "# query_params = {'query': '(from:twitterdev -is:retweet) OR #twitterdev','tweet.fields': 'author_id', \"max_results\":\"10\"}\n",
    "query_params = {\n",
    "#     'query': 'from:elonmusk -is:retweet is:verified',\n",
    "    'query' : '\"World Cup\" Brazil -is:retweet',\n",
    "    'tweet.fields': 'author_id', \n",
    "    'user.fields': 'name',\n",
    "    \"max_results\":\"25\",\n",
    "}\n",
    "\n",
    "def bearer_oauth(r):\n",
    "    \"\"\"\n",
    "    Method required by bearer token authentication.\n",
    "    \"\"\"\n",
    "\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2RecentSearchPython\"\n",
    "    return r\n",
    "\n",
    "def connect_to_endpoint(url, params):\n",
    "    response = requests.get(url, auth=bearer_oauth, params=params)\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "# Querying the API\n",
    "json_response = connect_to_endpoint(search_url, query_params)\n",
    "\n",
    "# Parsing the response\n",
    "parsedRes = json.dumps(json_response, indent=4, sort_keys=True, ensure_ascii=False)\n",
    "print(parsedRes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71073282",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T16:38:26.165471Z",
     "start_time": "2022-11-08T16:38:26.160467Z"
    }
   },
   "source": [
    "## Real Time Tweet Streams\n",
    "\n",
    "We are not limited to just historical tweets: we can collect tweets as they are sent! \n",
    "\n",
    "(I don't know the actual delay between tweet and stream, but it is relatively fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5e5b75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T18:21:17.036319Z",
     "start_time": "2022-11-08T18:21:17.029312Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install twitter-stream.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f91415",
   "metadata": {},
   "source": [
    "## SampledStream API\n",
    "Returns a constant stream of tweets, and returns certain properties of those tweets\n",
    "\n",
    "As is, it will keep going until the notebook kernal is stopped (though you can add in time limits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbd6362",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T18:20:09.993283Z",
     "start_time": "2022-11-08T18:18:27.349834Z"
    }
   },
   "outputs": [],
   "source": [
    "#Source: https://github.com/twitivity/twitter-stream.py\n",
    "# https://github.com/twitivity/twitter-stream.py/blob/main/twitter_stream.py\n",
    "\n",
    "import json\n",
    "from twitter_stream import SampledStream\n",
    "\n",
    "class Stream(SampledStream):\n",
    "    user_fields = ['name', 'location', 'public_metrics']\n",
    "    expansions = ['author_id']\n",
    "    tweet_fields = ['created_at']\n",
    "\n",
    "stream = Stream()\n",
    "for tweet in stream.connect():\n",
    "    print(json.dumps(tweet, indent=4,ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa753289",
   "metadata": {},
   "source": [
    "## FilteredStream API\n",
    "Returns a constant stream of tweets that have been filtered by some rules\n",
    "\n",
    "As is, it will keep going until the notebook kernal is stopped (though you can add in time limits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca52cd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T00:36:12.816672Z",
     "start_time": "2022-11-13T00:36:03.757430Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Source: https://github.com/twitivity/twitter-stream.py\n",
    "# https://github.com/twitivity/twitter-stream.py/blob/main/twitter_stream.py\n",
    "\n",
    "import json\n",
    "from twitter_stream import FilteredStream\n",
    "from time import time\n",
    "\n",
    "start = time()\n",
    "stream = FilteredStream()\n",
    "rule = {\n",
    "    \"add\" : [\n",
    "        {\"value\": \"\\\"World Cup\\\" -is:retweet\", \"tag\":\"soccer\"}\n",
    "    ]\n",
    "}\n",
    "stream.add_rule(data=rule)\n",
    "tweetList = []\n",
    "for tweet in stream.connect():\n",
    "    parsedTweet = json.dumps(tweet, indent=4,ensure_ascii=False)\n",
    "    tweetList.append(parsedTweet)\n",
    "    print(parsedTweet)\n",
    "    print(f\"There are: {len(tweetList)} tweets, about {len(tweetList)/(time()-start)} tweets per second after {(time()-start)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe1c302",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T23:26:37.060168Z",
     "start_time": "2022-11-08T23:26:37.048169Z"
    }
   },
   "outputs": [],
   "source": [
    "len(tweetList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2259d7c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T00:54:40.312025Z",
     "start_time": "2022-11-13T00:54:40.089789Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6572e5d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T17:22:51.342733Z",
     "start_time": "2022-11-08T17:22:51.330713Z"
    }
   },
   "outputs": [],
   "source": [
    "for tweet in searchTweetList:\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c273f22",
   "metadata": {},
   "source": [
    "REST API: Endpoint is watch, queries start at ? and are separated by &\n",
    "\n",
    "\n",
    "https://youtube.com/watch?v=dQw4w9WgXcQ&t=57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8968876",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T23:33:58.243698Z",
     "start_time": "2022-11-08T23:33:55.549551Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"Midterms Tweets.json\", \"w\") as file:\n",
    "    json.dump(tweetDict, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cf509e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
