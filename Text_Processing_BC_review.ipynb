{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing (Butter and Cheese Reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kftsu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "from string import punctuation\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('butter_cheese_review_ie.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I didn’t get the flavor I was expecting, espec...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kerrygold is not a dairy in Ireland. It is jus...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is an excellent butter for eating but ter...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I purchased an 8 oz at the local Kroger for 3....</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And I'm picky about the dairy I use. save your...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Brand Category\n",
       "0  I didn’t get the flavor I was expecting, espec...  Irish   Butter\n",
       "1  Kerrygold is not a dairy in Ireland. It is jus...  Irish   Butter\n",
       "2  This is an excellent butter for eating but ter...  Irish   Butter\n",
       "3  I purchased an 8 oz at the local Kroger for 3....  Irish   Butter\n",
       "4  And I'm picky about the dairy I use. save your...  Irish   Butter"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['word_count'] = train['Review'].apply(lambda x: len(str(x).split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I didn’t get the flavor I was expecting, espec...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kerrygold is not a dairy in Ireland. It is jus...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is an excellent butter for eating but ter...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I purchased an 8 oz at the local Kroger for 3....</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And I'm picky about the dairy I use. save your...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  word_count\n",
       "0  I didn’t get the flavor I was expecting, espec...          19\n",
       "1  Kerrygold is not a dairy in Ireland. It is jus...          75\n",
       "2  This is an excellent butter for eating but ter...          34\n",
       "3  I purchased an 8 oz at the local Kroger for 3....          38\n",
       "4  And I'm picky about the dairy I use. save your...          24"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding a column for the number of words of the review\n",
    "train[['Review','word_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['char_count'] = train['Review'].str.len() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I didn’t get the flavor I was expecting, espec...</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kerrygold is not a dairy in Ireland. It is jus...</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is an excellent butter for eating but ter...</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I purchased an 8 oz at the local Kroger for 3....</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And I'm picky about the dairy I use. save your...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  char_count\n",
       "0  I didn’t get the flavor I was expecting, espec...          97\n",
       "1  Kerrygold is not a dairy in Ireland. It is jus...         419\n",
       "2  This is an excellent butter for eating but ter...         181\n",
       "3  I purchased an 8 oz at the local Kroger for 3....         199\n",
       "4  And I'm picky about the dairy I use. save your...         115"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding a column for the number of characters of the review. This also includes spaces\n",
    "\n",
    "train[['Review','char_count']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Category</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I didn’t get the flavor I was expecting, espec...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>19</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kerrygold is not a dairy in Ireland. It is jus...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>75</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is an excellent butter for eating but ter...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>34</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I purchased an 8 oz at the local Kroger for 3....</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>38</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And I'm picky about the dairy I use. save your...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>24</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Brand Category  \\\n",
       "0  I didn’t get the flavor I was expecting, espec...  Irish   Butter   \n",
       "1  Kerrygold is not a dairy in Ireland. It is jus...  Irish   Butter   \n",
       "2  This is an excellent butter for eating but ter...  Irish   Butter   \n",
       "3  I purchased an 8 oz at the local Kroger for 3....  Irish   Butter   \n",
       "4  And I'm picky about the dairy I use. save your...  Irish   Butter   \n",
       "\n",
       "   word_count  char_count  \n",
       "0          19          97  \n",
       "1          75         419  \n",
       "2          34         181  \n",
       "3          38         199  \n",
       "4          24         115  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word(sentence):\n",
    "  words = sentence.split()\n",
    "  return (sum(len(word) for word in words)/len(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['avg_word'] = train['Review'].apply(lambda x: avg_word(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>avg_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I didn’t get the flavor I was expecting, espec...</td>\n",
       "      <td>4.157895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kerrygold is not a dairy in Ireland. It is jus...</td>\n",
       "      <td>4.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is an excellent butter for eating but ter...</td>\n",
       "      <td>4.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I purchased an 8 oz at the local Kroger for 3....</td>\n",
       "      <td>4.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And I'm picky about the dairy I use. save your...</td>\n",
       "      <td>3.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  avg_word\n",
       "0  I didn’t get the flavor I was expecting, espec...  4.157895\n",
       "1  Kerrygold is not a dairy in Ireland. It is jus...  4.600000\n",
       "2  This is an excellent butter for eating but ter...  4.352941\n",
       "3  I purchased an 8 oz at the local Kroger for 3....  4.263158\n",
       "4  And I'm picky about the dairy I use. save your...  3.833333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['Review','avg_word']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kftsu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means there are stopwords in the reviews.\n",
    "I wanted to look at the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I didn’t get the flavor I was expecting, espec...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kerrygold is not a dairy in Ireland. It is jus...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is an excellent butter for eating but ter...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I purchased an 8 oz at the local Kroger for 3....</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And I'm picky about the dairy I use. save your...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  stopwords\n",
       "0  I didn’t get the flavor I was expecting, espec...          7\n",
       "1  Kerrygold is not a dairy in Ireland. It is jus...         30\n",
       "2  This is an excellent butter for eating but ter...         14\n",
       "3  I purchased an 8 oz at the local Kroger for 3....         12\n",
       "4  And I'm picky about the dairy I use. save your...         12"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Counting the number of stop words\n",
    "\n",
    "train['stopwords'] = train['Review'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "train[['Review','stopwords']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>hastags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I didn’t get the flavor I was expecting, espec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kerrygold is not a dairy in Ireland. It is jus...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is an excellent butter for eating but ter...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I purchased an 8 oz at the local Kroger for 3....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And I'm picky about the dairy I use. save your...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  hastags\n",
       "0  I didn’t get the flavor I was expecting, espec...        0\n",
       "1  Kerrygold is not a dairy in Ireland. It is jus...        0\n",
       "2  This is an excellent butter for eating but ter...        0\n",
       "3  I purchased an 8 oz at the local Kroger for 3....        0\n",
       "4  And I'm picky about the dairy I use. save your...        0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Counting number of hashtags present in the review\n",
    "\n",
    "train['hastags'] = train['Review'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
    "train[['Review','hastags']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>numerics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I didn’t get the flavor I was expecting, espec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kerrygold is not a dairy in Ireland. It is jus...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is an excellent butter for eating but ter...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I purchased an 8 oz at the local Kroger for 3....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And I'm picky about the dairy I use. save your...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  numerics\n",
       "0  I didn’t get the flavor I was expecting, espec...         0\n",
       "1  Kerrygold is not a dairy in Ireland. It is jus...         0\n",
       "2  This is an excellent butter for eating but ter...         0\n",
       "3  I purchased an 8 oz at the local Kroger for 3....         1\n",
       "4  And I'm picky about the dairy I use. save your...         0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting the numerics in the review\n",
    "\n",
    "train['numerics'] = train['Review'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "train[['Review','numerics']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I didn’t get the flavor I was expecting, espec...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kerrygold is not a dairy in Ireland. It is jus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is an excellent butter for eating but ter...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I purchased an 8 oz at the local Kroger for 3....</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And I'm picky about the dairy I use. save your...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  upper\n",
       "0  I didn’t get the flavor I was expecting, espec...      3\n",
       "1  Kerrygold is not a dairy in Ireland. It is jus...      1\n",
       "2  This is an excellent butter for eating but ter...      1\n",
       "3  I purchased an 8 oz at the local Kroger for 3....      2\n",
       "4  And I'm picky about the dairy I use. save your...      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of uppercases present in reviews\n",
    "\n",
    "train['upper'] = train['Review'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "train[['Review','upper']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to transform uppercases to lowercase to avoid having multiple copies of the same words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i didn’t get the flavor i was expecting, espec...\n",
       "1    kerrygold is not a dairy in ireland. it is jus...\n",
       "2    this is an excellent butter for eating but ter...\n",
       "3    i purchased an 8 oz at the local kroger for 3....\n",
       "4    and i'm picky about the dairy i use. save your...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transforming uppercases to lowercase\n",
    "\n",
    "train['Review'] = train['Review'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "train['Review'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to remove special characters in the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kftsu\\AppData\\Local\\Temp\\ipykernel_25032\\3484550088.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train['Review'] = train['Review'].str.replace('[^\\w\\s]','')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    i didnt get the flavor i was expecting especia...\n",
       "1    kerrygold is not a dairy in ireland it is just...\n",
       "2    this is an excellent butter for eating but ter...\n",
       "3    i purchased an 8 oz at the local kroger for 39...\n",
       "4    and im picky about the dairy i use save your m...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing special characters\n",
    "\n",
    "train['Review'] = train['Review'].str.replace('[^\\w\\s]','')\n",
    "train['Review'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to make a list of stopwords so I can remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    didnt get flavor expecting especially price wa...\n",
       "1    kerrygold dairy ireland umbrella marketing bra...\n",
       "2    excellent butter eating terrible baking makes ...\n",
       "3    purchased 8 oz local kroger 399 also purchased...\n",
       "4    im picky dairy use save money good cheaper eve...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "train['Review'] = train['Review'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "train['Review'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to remove the common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "butter       53\n",
       "great        15\n",
       "taste        15\n",
       "good         10\n",
       "like          9\n",
       "use           8\n",
       "well          8\n",
       "love          7\n",
       "kerrygold     7\n",
       "brand         7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count of common words\n",
    "freq = pd.Series(' '.join(train['Review']).split()).value_counts()[:10]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    didnt get flavor expecting especially price wa...\n",
       "1    dairy ireland umbrella marketing brandname man...\n",
       "2    excellent eating terrible baking makes cookies...\n",
       "3    purchased 8 oz local kroger 399 also purchased...\n",
       "4        im picky dairy save money cheaper even better\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing the most common words\n",
    "\n",
    "freq = list(freq.index)\n",
    "train['Review'] = train['Review'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "train['Review'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the common words are removed as their presence will not of any use in classification of my text data.\n",
    "\n",
    "Next, I wanted to remove the rare words. This is because the association between these rare words and other words is dominated by noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reading     1\n",
       "tried       1\n",
       "today       1\n",
       "lol         1\n",
       "problem     1\n",
       "italian     1\n",
       "cheeseby    1\n",
       "anymore     1\n",
       "probobly    1\n",
       "result      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(train['Review']).split()).value_counts()[-10:]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    didnt get flavor expecting especially price wa...\n",
       "1    dairy ireland umbrella marketing brandname man...\n",
       "2    excellent eating terrible baking makes cookies...\n",
       "3    purchased 8 oz local kroger 399 also purchased...\n",
       "4        im picky dairy save money cheaper even better\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing the most rare words\n",
    "\n",
    "freq = list(freq.index)\n",
    "train['Review'] = train['Review'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "train['Review'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to correct spelling of the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    didn get flavor expecting especially price wan...\n",
       "1    dairy ireland umbrella marketing brandname man...\n",
       "2    excellent eating terrible baking makes colonie...\n",
       "3    purchased 8 oz local roger 399 also purchased ...\n",
       "4         in pick dairy save money cheaper even better\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#correcting spelling\n",
    "\n",
    "from textblob import TextBlob\n",
    "train['Review'][:5].apply(lambda x: str(TextBlob(x).correct()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization\n",
    "-dividing the text into a sequence of words or sentences. (From David's lecture notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kftsu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WordList(['dairy', 'ireland', 'umbrella', 'marketing', 'brandname', 'many', 'different', 'dairies', 'europe', 'considered', 'premium', 'ordinary', 'yellower', 'color', 'american', 'butters', 'ill', 'give', 'disappointing', 'many', 'common', 'brands', 'even', 'kind', 'served', 'cafeterias', 'much', 'better', 'wont', 'purchasing'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenization\n",
    "\n",
    "nltk.download('punkt')\n",
    "TextBlob(train['Review'][1]).words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming\n",
    "-removal of suffices, like “ing”, “ly”, “s”, etc. by a simple rule-based \n",
    "approach. For this purpose, I will use PorterStemmer from the NLTK library. (From David's Lecture notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       didnt get flavor expect especi price want much\n",
       "1    dairi ireland umbrella market brandnam mani di...\n",
       "2    excel eat terribl bake make cooki fall apart l...\n",
       "3    purchas 8 oz local kroger 399 also purchas pou...\n",
       "4        im picki dairi save money cheaper even better\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stemming\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "st = PorterStemmer()\n",
    "train['Review'][:5].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization\n",
    "-converts the word into its root word, rather than just stripping the suffices. It makes use of the vocabulary and does a morphological analysis to obtain the root word (From David's Lecture notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kftsu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**********************************************************************\n",
      "  Resource \u001b[93momw-1.4\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('omw-1.4')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\kftsu/nltk_data'\n",
      "    - 'C:\\\\Users\\\\kftsu\\\\anaconda3\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\kftsu\\\\anaconda3\\\\share\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\kftsu\\\\anaconda3\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\kftsu\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "**********************************************************************\n",
      "\n"
     ]
    },
    {
     "ename": "MissingCorpusError",
     "evalue": "\nLooks like you are missing some required data for this feature.\n\nTo download the necessary data, simply run\n\n    python -m textblob.download_corpora\n\nor use the NLTK downloader to download the missing data: http://nltk.org/data.html\nIf this doesn't fix the problem, file an issue at https://github.com/sloria/TextBlob/issues.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 84\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4.zip/omw-1.4/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\kftsu/nltk_data'\n    - 'C:\\\\Users\\\\kftsu\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\kftsu\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\kftsu\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\kftsu\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textblob\\decorators.py:35\u001b[0m, in \u001b[0;36mrequires_nltk_corpus.<locals>.decorated\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textblob\\blob.py:161\u001b[0m, in \u001b[0;36mWord.lemmatize\u001b[1;34m(self, pos)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     tag \u001b[38;5;241m=\u001b[39m \u001b[43m_wordnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNOUN\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pos \u001b[38;5;129;01min\u001b[39;00m _wordnet\u001b[38;5;241m.\u001b[39m_FILEMAP\u001b[38;5;241m.\u001b[39mkeys():\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:89\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[1;32m---> 89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# This is where the magic happens!  Transform ourselves into\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# the corpus by modifying our own __dict__ and __class__ to\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# match that of the corpus.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py:1176\u001b[0m, in \u001b[0;36mWordNetCorpusReader.__init__\u001b[1;34m(self, root, omw_reader)\u001b[0m\n\u001b[0;32m   1175\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprovenances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43momw_prov\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;66;03m# A cache to store the wordnet data of multiple languages\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py:1285\u001b[0m, in \u001b[0;36mWordNetCorpusReader.omw_prov\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1284\u001b[0m provdict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1285\u001b[0m fileids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_omw_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfileids\u001b[49m()\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fileid \u001b[38;5;129;01min\u001b[39;00m fileids:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\kftsu/nltk_data'\n    - 'C:\\\\Users\\\\kftsu\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\kftsu\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\kftsu\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\kftsu\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMissingCorpusError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwordnet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextblob\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Word\n\u001b[1;32m----> 5\u001b[0m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReview\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mReview\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mWord\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReview\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      3\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwordnet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextblob\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Word\n\u001b[1;32m----> 5\u001b[0m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReview\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReview\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([Word(word)\u001b[38;5;241m.\u001b[39mlemmatize() \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39msplit()]))\n\u001b[0;32m      6\u001b[0m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReview\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mhead()\n",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwordnet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextblob\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Word\n\u001b[1;32m----> 5\u001b[0m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReview\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReview\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[43mWord\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39msplit()]))\n\u001b[0;32m      6\u001b[0m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReview\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\textblob\\decorators.py:38\u001b[0m, in \u001b[0;36mrequires_nltk_corpus.<locals>.decorated\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(err)\n\u001b[1;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingCorpusError()\n",
      "\u001b[1;31mMissingCorpusError\u001b[0m: \nLooks like you are missing some required data for this feature.\n\nTo download the necessary data, simply run\n\n    python -m textblob.download_corpora\n\nor use the NLTK downloader to download the missing data: http://nltk.org/data.html\nIf this doesn't fix the problem, file an issue at https://github.com/sloria/TextBlob/issues.\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "\n",
    "nltk.download('wordnet')\n",
    "from textblob import Word\n",
    "train['Review'] = train['Review'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "train['Review'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to extract bigrams from the reviews using the ngrams function of the textblob. I wanted to capture the language structure, like what letter or word is likely to follow the given one. I wanted to work with bigrams to capture general knowlege. (From David's lecture notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['didnt', 'get']),\n",
       " WordList(['get', 'flavor']),\n",
       " WordList(['flavor', 'expecting']),\n",
       " WordList(['expecting', 'especially']),\n",
       " WordList(['especially', 'price']),\n",
       " WordList(['price', 'wanted']),\n",
       " WordList(['wanted', 'much'])]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(train['Review'][0]).ngrams(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term frequency\n",
    "-the ratio of the count of a word present in a sentence, to the length of the sentence. (From David's lecture notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>many</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dairy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>butters</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wont</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>better</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>much</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cafeterias</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>served</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kind</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>even</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>brands</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>common</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>disappointing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>give</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ill</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>american</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ireland</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>color</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>yellower</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ordinary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>premium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>considered</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>europe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>dairies</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>different</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>brandname</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>marketing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>umbrella</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>purchasing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            words  tf\n",
       "0            many   2\n",
       "1           dairy   1\n",
       "2         butters   1\n",
       "3            wont   1\n",
       "4          better   1\n",
       "5            much   1\n",
       "6      cafeterias   1\n",
       "7          served   1\n",
       "8            kind   1\n",
       "9            even   1\n",
       "10         brands   1\n",
       "11         common   1\n",
       "12  disappointing   1\n",
       "13           give   1\n",
       "14            ill   1\n",
       "15       american   1\n",
       "16        ireland   1\n",
       "17          color   1\n",
       "18       yellower   1\n",
       "19       ordinary   1\n",
       "20        premium   1\n",
       "21     considered   1\n",
       "22         europe   1\n",
       "23        dairies   1\n",
       "24      different   1\n",
       "25      brandname   1\n",
       "26      marketing   1\n",
       "27       umbrella   1\n",
       "28     purchasing   1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#term frequency\n",
    "\n",
    "tf1 = (train['Review'][1:2]).apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0).reset_index()\n",
    "tf1.columns = ['words','tf']\n",
    "tf1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inverse Document Frequency (IDF)\n",
    "-the log of the ratio of the total number of rows to the \n",
    "number of rows in which that word is present. The more the value of IDF, the more unique is the word. (From David's Lecture notes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>many</td>\n",
       "      <td>2</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dairy</td>\n",
       "      <td>1</td>\n",
       "      <td>2.813411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>butters</td>\n",
       "      <td>1</td>\n",
       "      <td>3.218876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wont</td>\n",
       "      <td>1</td>\n",
       "      <td>3.218876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>better</td>\n",
       "      <td>1</td>\n",
       "      <td>2.525729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>much</td>\n",
       "      <td>1</td>\n",
       "      <td>2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cafeterias</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>served</td>\n",
       "      <td>1</td>\n",
       "      <td>2.813411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kind</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>even</td>\n",
       "      <td>1</td>\n",
       "      <td>2.525729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>brands</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>common</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>disappointing</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>give</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ill</td>\n",
       "      <td>1</td>\n",
       "      <td>2.525729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>american</td>\n",
       "      <td>1</td>\n",
       "      <td>3.218876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ireland</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>color</td>\n",
       "      <td>1</td>\n",
       "      <td>2.525729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>yellower</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ordinary</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>premium</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>considered</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>europe</td>\n",
       "      <td>1</td>\n",
       "      <td>3.218876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>dairies</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>different</td>\n",
       "      <td>1</td>\n",
       "      <td>3.218876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>brandname</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>marketing</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>umbrella</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>purchasing</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            words  tf       idf\n",
       "0            many   2  3.912023\n",
       "1           dairy   1  2.813411\n",
       "2         butters   1  3.218876\n",
       "3            wont   1  3.218876\n",
       "4          better   1  2.525729\n",
       "5            much   1  2.302585\n",
       "6      cafeterias   1  3.912023\n",
       "7          served   1  2.813411\n",
       "8            kind   1  3.912023\n",
       "9            even   1  2.525729\n",
       "10         brands   1  3.912023\n",
       "11         common   1  3.912023\n",
       "12  disappointing   1  3.912023\n",
       "13           give   1  3.912023\n",
       "14            ill   1  2.525729\n",
       "15       american   1  3.218876\n",
       "16        ireland   1  3.912023\n",
       "17          color   1  2.525729\n",
       "18       yellower   1  3.912023\n",
       "19       ordinary   1  3.912023\n",
       "20        premium   1  3.912023\n",
       "21     considered   1  3.912023\n",
       "22         europe   1  3.218876\n",
       "23        dairies   1  3.912023\n",
       "24      different   1  3.218876\n",
       "25      brandname   1  3.912023\n",
       "26      marketing   1  3.912023\n",
       "27       umbrella   1  3.912023\n",
       "28     purchasing   1  3.912023"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting IDF\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "for i,word in enumerate(tf1['words']):\n",
    "  tf1.loc[i, 'idf'] = np.log(train.shape[0]/(len(train[train['Review'].str.contains(word)])))\n",
    "\n",
    "tf1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF\n",
    "-the multiplication of the TF and IDF calculated above.The importance of a term is inversely related to its frequency across documents (Capitalone.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "      <th>idf</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>many</td>\n",
       "      <td>2</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>7.824046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dairy</td>\n",
       "      <td>1</td>\n",
       "      <td>2.813411</td>\n",
       "      <td>2.813411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>butters</td>\n",
       "      <td>1</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>3.218876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wont</td>\n",
       "      <td>1</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>3.218876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>better</td>\n",
       "      <td>1</td>\n",
       "      <td>2.525729</td>\n",
       "      <td>2.525729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>much</td>\n",
       "      <td>1</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cafeterias</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>served</td>\n",
       "      <td>1</td>\n",
       "      <td>2.813411</td>\n",
       "      <td>2.813411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kind</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>even</td>\n",
       "      <td>1</td>\n",
       "      <td>2.525729</td>\n",
       "      <td>2.525729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>brands</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>common</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>disappointing</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>give</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ill</td>\n",
       "      <td>1</td>\n",
       "      <td>2.525729</td>\n",
       "      <td>2.525729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>american</td>\n",
       "      <td>1</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>3.218876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ireland</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>color</td>\n",
       "      <td>1</td>\n",
       "      <td>2.525729</td>\n",
       "      <td>2.525729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>yellower</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ordinary</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>premium</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>considered</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>europe</td>\n",
       "      <td>1</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>3.218876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>dairies</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>different</td>\n",
       "      <td>1</td>\n",
       "      <td>3.218876</td>\n",
       "      <td>3.218876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>brandname</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>marketing</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>umbrella</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>purchasing</td>\n",
       "      <td>1</td>\n",
       "      <td>3.912023</td>\n",
       "      <td>3.912023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            words  tf       idf     tfidf\n",
       "0            many   2  3.912023  7.824046\n",
       "1           dairy   1  2.813411  2.813411\n",
       "2         butters   1  3.218876  3.218876\n",
       "3            wont   1  3.218876  3.218876\n",
       "4          better   1  2.525729  2.525729\n",
       "5            much   1  2.302585  2.302585\n",
       "6      cafeterias   1  3.912023  3.912023\n",
       "7          served   1  2.813411  2.813411\n",
       "8            kind   1  3.912023  3.912023\n",
       "9            even   1  2.525729  2.525729\n",
       "10         brands   1  3.912023  3.912023\n",
       "11         common   1  3.912023  3.912023\n",
       "12  disappointing   1  3.912023  3.912023\n",
       "13           give   1  3.912023  3.912023\n",
       "14            ill   1  2.525729  2.525729\n",
       "15       american   1  3.218876  3.218876\n",
       "16        ireland   1  3.912023  3.912023\n",
       "17          color   1  2.525729  2.525729\n",
       "18       yellower   1  3.912023  3.912023\n",
       "19       ordinary   1  3.912023  3.912023\n",
       "20        premium   1  3.912023  3.912023\n",
       "21     considered   1  3.912023  3.912023\n",
       "22         europe   1  3.218876  3.218876\n",
       "23        dairies   1  3.912023  3.912023\n",
       "24      different   1  3.218876  3.218876\n",
       "25      brandname   1  3.912023  3.912023\n",
       "26      marketing   1  3.912023  3.912023\n",
       "27       umbrella   1  3.912023  3.912023\n",
       "28     purchasing   1  3.912023  3.912023"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf1['tfidf'] = tf1['tf'] * tf1['idf']\n",
    "tf1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Words (BoW)\n",
    "-representation of text which describes the presence of words within the text data. The intuition behind this is that two similar text fields will contain similar kind of words, and will therefore have a similar bag of words. (From David's Lecture notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<50x348 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 483 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',\n",
    " stop_words= 'english',ngram_range=(1,1))\n",
    "train_vect = tfidf.fit_transform(train['Review'])\n",
    "\n",
    "train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 330)\t0.4316670407335372\n",
      "  (0, 239)\t0.4316670407335372\n",
      "  (0, 107)\t0.4316670407335372\n",
      "  (0, 113)\t0.3903744715252307\n",
      "  (0, 130)\t0.31978435821471934\n",
      "  (0, 88)\t0.4316670407335372\n",
      "  (1, 246)\t0.2076146568732704\n",
      "  (1, 340)\t0.18775457542477667\n",
      "  (1, 29)\t0.16273383186115575\n",
      "  (1, 46)\t0.2076146568732704\n",
      "  (1, 278)\t0.2076146568732704\n",
      "  (1, 174)\t0.2076146568732704\n",
      "  (1, 36)\t0.2076146568732704\n",
      "  (1, 60)\t0.2076146568732704\n",
      "  (1, 92)\t0.2076146568732704\n",
      "  (1, 161)\t0.2076146568732704\n",
      "  (1, 42)\t0.18775457542477667\n",
      "  (1, 16)\t0.18775457542477667\n",
      "  (1, 58)\t0.16273383186115575\n",
      "  (1, 345)\t0.2076146568732704\n",
      "  (1, 220)\t0.2076146568732704\n",
      "  (1, 237)\t0.2076146568732704\n",
      "  (1, 65)\t0.2076146568732704\n",
      "  (1, 109)\t0.2076146568732704\n",
      "  (1, 79)\t0.2076146568732704\n",
      "  :\t:\n",
      "  (43, 318)\t0.26957497045151596\n",
      "  (43, 243)\t0.22702608343277972\n",
      "  (44, 238)\t0.5773502691896257\n",
      "  (44, 7)\t0.5773502691896257\n",
      "  (44, 191)\t0.5773502691896257\n",
      "  (45, 282)\t0.7556627889402567\n",
      "  (45, 29)\t0.6549608762445532\n",
      "  (46, 106)\t0.4257240111788281\n",
      "  (46, 11)\t0.4257240111788281\n",
      "  (46, 242)\t0.4257240111788281\n",
      "  (46, 197)\t0.4257240111788281\n",
      "  (46, 100)\t0.38499994254165115\n",
      "  (46, 69)\t0.3561057560138025\n",
      "  (48, 49)\t0.5745746121652983\n",
      "  (48, 44)\t0.44756998293552874\n",
      "  (48, 317)\t0.49800505855186483\n",
      "  (48, 33)\t0.4706762019551673\n",
      "  (49, 336)\t0.3917624125616578\n",
      "  (49, 255)\t0.3917624125616578\n",
      "  (49, 341)\t0.3917624125616578\n",
      "  (49, 344)\t0.32092132250400696\n",
      "  (49, 209)\t0.32092132250400696\n",
      "  (49, 286)\t0.32092132250400696\n",
      "  (49, 77)\t0.3395549665359394\n",
      "  (49, 58)\t0.3395549665359394\n"
     ]
    }
   ],
   "source": [
    "print(train_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<50x392 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 562 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1,1),analyzer = \"word\")\n",
    "train_bow = bow.fit_transform(train['Review'])\n",
    "train_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 97)\t1\n",
      "  (0, 164)\t1\n",
      "  (0, 147)\t1\n",
      "  (0, 128)\t1\n",
      "  (0, 118)\t1\n",
      "  (0, 272)\t1\n",
      "  (0, 370)\t1\n",
      "  (0, 236)\t1\n",
      "  (1, 236)\t1\n",
      "  (1, 89)\t1\n",
      "  (1, 191)\t1\n",
      "  (1, 364)\t1\n",
      "  (1, 228)\t1\n",
      "  (1, 41)\t1\n",
      "  (1, 226)\t2\n",
      "  (1, 98)\t1\n",
      "  (1, 88)\t1\n",
      "  (1, 120)\t1\n",
      "  (1, 73)\t1\n",
      "  (1, 270)\t1\n",
      "  (1, 253)\t1\n",
      "  (1, 388)\t1\n",
      "  (1, 66)\t1\n",
      "  (1, 18)\t1\n",
      "  (1, 48)\t1\n",
      "  :\t:\n",
      "  (44, 271)\t1\n",
      "  (45, 35)\t1\n",
      "  (45, 320)\t1\n",
      "  (46, 77)\t1\n",
      "  (46, 109)\t1\n",
      "  (46, 225)\t1\n",
      "  (46, 275)\t1\n",
      "  (46, 11)\t1\n",
      "  (46, 116)\t1\n",
      "  (48, 39)\t1\n",
      "  (48, 146)\t1\n",
      "  (48, 357)\t1\n",
      "  (48, 50)\t1\n",
      "  (48, 55)\t1\n",
      "  (49, 66)\t1\n",
      "  (49, 15)\t1\n",
      "  (49, 86)\t1\n",
      "  (49, 324)\t1\n",
      "  (49, 240)\t1\n",
      "  (49, 387)\t1\n",
      "  (49, 281)\t1\n",
      "  (49, 383)\t1\n",
      "  (49, 290)\t1\n",
      "  (49, 28)\t1\n",
      "  (49, 377)\t1\n"
     ]
    }
   ],
   "source": [
    "print(train_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     (0.1, 0.6)\n",
       "1     (0.045000000000000005, 0.5700000000000001)\n",
       "2      (0.09999999999999999, 0.7666666666666666)\n",
       "3    (-0.03714285714285713, 0.22000000000000003)\n",
       "4                                     (0.5, 0.5)\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Review'][:5].apply(lambda x: TextBlob(x).sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>didnt get flavor expecting especially price wa...</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dairy ireland umbrella marketing brandname man...</td>\n",
       "      <td>0.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>excellent eating terrible baking makes cookies...</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>purchased 8 oz local kroger 399 also purchased...</td>\n",
       "      <td>-0.037143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im picky dairy save money cheaper even better</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  sentiment\n",
       "0  didnt get flavor expecting especially price wa...   0.100000\n",
       "1  dairy ireland umbrella marketing brandname man...   0.045000\n",
       "2  excellent eating terrible baking makes cookies...   0.100000\n",
       "3  purchased 8 oz local kroger 399 also purchased...  -0.037143\n",
       "4      im picky dairy save money cheaper even better   0.500000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['sentiment'] = train['Review'].apply(lambda x: TextBlob(x).sentiment[0] )\n",
    "train[['Review','sentiment']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Category</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>hastags</th>\n",
       "      <th>numerics</th>\n",
       "      <th>upper</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>didnt get flavor expecting especially price wa...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>19</td>\n",
       "      <td>97</td>\n",
       "      <td>4.157895</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dairy ireland umbrella marketing brandname man...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>75</td>\n",
       "      <td>419</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>excellent eating terrible baking makes cookies...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>34</td>\n",
       "      <td>181</td>\n",
       "      <td>4.352941</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>purchased 8 oz local kroger 399 also purchased...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>38</td>\n",
       "      <td>199</td>\n",
       "      <td>4.263158</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.037143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im picky dairy save money cheaper even better</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>24</td>\n",
       "      <td>115</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>drastically priced</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dont know pricey</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>11</td>\n",
       "      <td>54</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ive read 90 grass fed finished soy corn women ...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>38</td>\n",
       "      <td>218</td>\n",
       "      <td>4.763158</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>creamy smooth texture nice</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tastes creamer get buying dealer found costco ...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>24</td>\n",
       "      <td>130</td>\n",
       "      <td>4.458333</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>really</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>thought buying tub easily spread although flav...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>23</td>\n",
       "      <td>121</td>\n",
       "      <td>4.304348</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wish could find unsalted</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>last refrig longtiime</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>13</td>\n",
       "      <td>59</td>\n",
       "      <td>3.615385</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>friend recommended</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bought sams club trying friends houseshe said ...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>189</td>\n",
       "      <td>964</td>\n",
       "      <td>4.105820</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.258333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>first time ive high omega3 content course gras...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>63</td>\n",
       "      <td>326</td>\n",
       "      <td>4.190476</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bought lark amazon pleasantly surprised mild s...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>114</td>\n",
       "      <td>626</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.204762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>longer buy state live wisconsin dairy state do...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>113</td>\n",
       "      <td>544</td>\n",
       "      <td>3.823009</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.105328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>excellent compares anchor new zealand maybe ev...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>95</td>\n",
       "      <td>525</td>\n",
       "      <td>4.536842</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.469481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>simply delicious salty bland perfect quite bit...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>39</td>\n",
       "      <td>202</td>\n",
       "      <td>4.205128</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>everything right shipped right away cold ready...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>30</td>\n",
       "      <td>145</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.074286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>outstanding seller outstanding product came ru...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>51</td>\n",
       "      <td>293</td>\n",
       "      <td>4.764706</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tasting came extreme box ice pack insulated pa...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>43</td>\n",
       "      <td>220</td>\n",
       "      <td>4.139535</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.177885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>grass feed thing dont finishes quickly larger tub</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>31</td>\n",
       "      <td>148</td>\n",
       "      <td>3.806452</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>huge fan cook spreading bread crackers toast w...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>70</td>\n",
       "      <td>360</td>\n",
       "      <td>4.157143</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.136111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>kerry gold wish could afford get often</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>18</td>\n",
       "      <td>89</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>arrived packed cold put fridge days spot freez...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>27</td>\n",
       "      <td>128</td>\n",
       "      <td>3.777778</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>smooth buttery</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>best far using keto way eating</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>12</td>\n",
       "      <td>55</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>liquid</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tasted fake horrible</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>first time bought canned buy</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>19</td>\n",
       "      <td>97</td>\n",
       "      <td>4.157895</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>smooth works recipes also put back winter nice...</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>30</td>\n",
       "      <td>158</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>soft easy spread</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>wife</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td></td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>product expensive expecting lot flavor</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>15</td>\n",
       "      <td>80</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>expected</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tastes made</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>rich cant stop putting cookies</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>11</td>\n",
       "      <td>55</td>\n",
       "      <td>4.090909</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>tasting bit expensive side amount surely make ...</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>20</td>\n",
       "      <td>107</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>mom buy dutch came round yellow cow design fro...</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>50</td>\n",
       "      <td>240</td>\n",
       "      <td>3.820000</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.261111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>product comes clear using toast omelet dish fl...</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>28</td>\n",
       "      <td>150</td>\n",
       "      <td>4.392857</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>loved ability keep preserved</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>11</td>\n",
       "      <td>60</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>simply better</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>making cookies produced addition end dutch</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>14</td>\n",
       "      <td>80</td>\n",
       "      <td>4.785714</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td></td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>first time bought canned buy</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>19</td>\n",
       "      <td>97</td>\n",
       "      <td>4.157895</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>smooth works recipes also put back winter nice...</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>30</td>\n",
       "      <td>158</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Review  Brand Category  \\\n",
       "0   didnt get flavor expecting especially price wa...  Irish   Butter   \n",
       "1   dairy ireland umbrella marketing brandname man...  Irish   Butter   \n",
       "2   excellent eating terrible baking makes cookies...  Irish   Butter   \n",
       "3   purchased 8 oz local kroger 399 also purchased...  Irish   Butter   \n",
       "4       im picky dairy save money cheaper even better  Irish   Butter   \n",
       "5                                  drastically priced  Irish   Butter   \n",
       "6                                    dont know pricey  Irish   Butter   \n",
       "7   ive read 90 grass fed finished soy corn women ...  Irish   Butter   \n",
       "8                          creamy smooth texture nice  Irish   Butter   \n",
       "9   tastes creamer get buying dealer found costco ...  Irish   Butter   \n",
       "10                                             really  Irish   Butter   \n",
       "11  thought buying tub easily spread although flav...  Irish   Butter   \n",
       "12                           wish could find unsalted  Irish   Butter   \n",
       "13                              last refrig longtiime  Irish   Butter   \n",
       "14                                 friend recommended  Irish   Butter   \n",
       "15  bought sams club trying friends houseshe said ...  Irish   Butter   \n",
       "16  first time ive high omega3 content course gras...  Irish   Butter   \n",
       "17  bought lark amazon pleasantly surprised mild s...  Irish   Butter   \n",
       "18  longer buy state live wisconsin dairy state do...  Irish   Butter   \n",
       "19  excellent compares anchor new zealand maybe ev...  Irish   Butter   \n",
       "20  simply delicious salty bland perfect quite bit...  Irish   Butter   \n",
       "21  everything right shipped right away cold ready...  Irish   Butter   \n",
       "22  outstanding seller outstanding product came ru...  Irish   Butter   \n",
       "23  tasting came extreme box ice pack insulated pa...  Irish   Butter   \n",
       "24  grass feed thing dont finishes quickly larger tub  Irish   Butter   \n",
       "25  huge fan cook spreading bread crackers toast w...  Irish   Butter   \n",
       "26             kerry gold wish could afford get often  Irish   Butter   \n",
       "27  arrived packed cold put fridge days spot freez...  Irish   Butter   \n",
       "28                                     smooth buttery  Irish   Butter   \n",
       "29                     best far using keto way eating  Irish   Butter   \n",
       "30                                             liquid  Dutch   Butter   \n",
       "31                               tasted fake horrible  Dutch   Butter   \n",
       "32                       first time bought canned buy  Dutch   Butter   \n",
       "33  smooth works recipes also put back winter nice...  Dutch   Butter   \n",
       "34                                   soft easy spread  Dutch   Butter   \n",
       "35                                               wife  Dutch   Butter   \n",
       "36                                                     Dutch   Butter   \n",
       "37             product expensive expecting lot flavor  Dutch   Butter   \n",
       "38                                           expected  Dutch   Butter   \n",
       "39                                        tastes made  Dutch   Butter   \n",
       "40                     rich cant stop putting cookies  Dutch   Butter   \n",
       "41  tasting bit expensive side amount surely make ...  Dutch   Butter   \n",
       "42  mom buy dutch came round yellow cow design fro...  Dutch   Butter   \n",
       "43  product comes clear using toast omelet dish fl...  Dutch   Butter   \n",
       "44                       loved ability keep preserved  Dutch   Butter   \n",
       "45                                      simply better  Dutch   Butter   \n",
       "46         making cookies produced addition end dutch  Dutch   Butter   \n",
       "47                                                     Dutch   Butter   \n",
       "48                       first time bought canned buy  Dutch   Butter   \n",
       "49  smooth works recipes also put back winter nice...  Dutch   Butter   \n",
       "\n",
       "    word_count  char_count  avg_word  stopwords  hastags  numerics  upper  \\\n",
       "0           19          97  4.157895          7        0         0      3   \n",
       "1           75         419  4.600000         30        0         0      1   \n",
       "2           34         181  4.352941         14        0         0      1   \n",
       "3           38         199  4.263158         12        0         1      2   \n",
       "4           24         115  3.833333         12        0         0      1   \n",
       "5            3          23  7.000000          1        0         0      0   \n",
       "6           11          54  4.000000          6        0         0      1   \n",
       "7           38         218  4.763158         13        0         0      0   \n",
       "8            6          38  5.500000          0        0         0      0   \n",
       "9           24         130  4.458333         11        0         0      0   \n",
       "10           3          18  5.333333          0        0         0      0   \n",
       "11          23         121  4.304348          8        0         0      2   \n",
       "12           5          30  5.200000          0        0         0      1   \n",
       "13          13          59  3.615385          6        0         0      0   \n",
       "14           9          53  5.000000          4        0         0      0   \n",
       "15         189         964  4.105820         86        0         0      8   \n",
       "16          63         326  4.190476         29        0         0      1   \n",
       "17         114         626  4.500000         48        0         0      7   \n",
       "18         113         544  3.823009         49        0         1      7   \n",
       "19          95         525  4.536842         38        0         0      1   \n",
       "20          39         202  4.205128         15        0         0      3   \n",
       "21          30         145  3.866667          2        0         0     26   \n",
       "22          51         293  4.764706         20        0         0      0   \n",
       "23          43         220  4.139535         14        0         0      3   \n",
       "24          31         148  3.806452         13        0         0      2   \n",
       "25          70         360  4.157143         27        0         0      3   \n",
       "26          18          89  4.000000          6        0         0      1   \n",
       "27          27         128  3.777778         13        0         0      1   \n",
       "28           4          26  5.750000          0        0         0      0   \n",
       "29          12          55  3.666667          5        0         0      1   \n",
       "30           1           6  6.000000          0        0         0      0   \n",
       "31           4          24  5.250000          1        0         0      0   \n",
       "32          19          97  4.157895          6        0         0      2   \n",
       "33          30         158  4.300000         11        0         0      0   \n",
       "34           5          23  3.800000          2        0         0      0   \n",
       "35           4          15  3.000000          1        0         0      0   \n",
       "36           2          12  5.500000          0        0         0      0   \n",
       "37          15          80  4.400000          6        0         0      1   \n",
       "38           3          17  5.000000          1        0         0      0   \n",
       "39           8          37  3.750000          3        0         0      0   \n",
       "40          11          55  4.090909          5        0         0      0   \n",
       "41          20         107  4.400000          8        0         0      1   \n",
       "42          50         240  3.820000         24        0         0      1   \n",
       "43          28         150  4.392857         13        0         0      0   \n",
       "44          11          60  4.545455          4        0         0      0   \n",
       "45           3          19  5.666667          0        0         0      0   \n",
       "46          14          80  4.785714          5        0         0      0   \n",
       "47           2           7  3.000000          1        0         0      0   \n",
       "48          19          97  4.157895          6        0         0      2   \n",
       "49          30         158  4.300000         11        0         0      0   \n",
       "\n",
       "    sentiment  \n",
       "0    0.100000  \n",
       "1    0.045000  \n",
       "2    0.100000  \n",
       "3   -0.037143  \n",
       "4    0.500000  \n",
       "5    0.000000  \n",
       "6    0.000000  \n",
       "7   -0.312500  \n",
       "8    0.500000  \n",
       "9    0.000000  \n",
       "10   0.200000  \n",
       "11   0.433333  \n",
       "12   0.400000  \n",
       "13   0.000000  \n",
       "14   0.000000  \n",
       "15   0.258333  \n",
       "16   0.046481  \n",
       "17   0.204762  \n",
       "18   0.105328  \n",
       "19   0.469481  \n",
       "20   0.708333  \n",
       "21   0.074286  \n",
       "22   0.350000  \n",
       "23  -0.177885  \n",
       "24   0.000000  \n",
       "25   0.136111  \n",
       "26   0.000000  \n",
       "27  -0.600000  \n",
       "28   0.400000  \n",
       "29   0.550000  \n",
       "30   0.000000  \n",
       "31  -0.750000  \n",
       "32   0.250000  \n",
       "33   0.250000  \n",
       "34   0.266667  \n",
       "35   0.000000  \n",
       "36   0.000000  \n",
       "37  -0.500000  \n",
       "38  -0.100000  \n",
       "39   0.000000  \n",
       "40   0.375000  \n",
       "41   0.333333  \n",
       "42   0.261111  \n",
       "43   0.483333  \n",
       "44   0.700000  \n",
       "45   0.500000  \n",
       "46   0.000000  \n",
       "47   0.000000  \n",
       "48   0.250000  \n",
       "49   0.250000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding polarity rating\n",
    "\n",
    "train['Polarity_Rating'] = train['sentiment'].apply(lambda x: 'Positive' if x > 0 else('Neutral' if x == 0 else 'Negative'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Category</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>hastags</th>\n",
       "      <th>numerics</th>\n",
       "      <th>upper</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Polarity_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>didnt get flavor expecting especially price wa...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>19</td>\n",
       "      <td>97</td>\n",
       "      <td>4.157895</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dairy ireland umbrella marketing brandname man...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>75</td>\n",
       "      <td>419</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>excellent eating terrible baking makes cookies...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>34</td>\n",
       "      <td>181</td>\n",
       "      <td>4.352941</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>purchased 8 oz local kroger 399 also purchased...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>38</td>\n",
       "      <td>199</td>\n",
       "      <td>4.263158</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.037143</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im picky dairy save money cheaper even better</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>24</td>\n",
       "      <td>115</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>drastically priced</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dont know pricey</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>11</td>\n",
       "      <td>54</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ive read 90 grass fed finished soy corn women ...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>38</td>\n",
       "      <td>218</td>\n",
       "      <td>4.763158</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>creamy smooth texture nice</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tastes creamer get buying dealer found costco ...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>24</td>\n",
       "      <td>130</td>\n",
       "      <td>4.458333</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>really</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>thought buying tub easily spread although flav...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>23</td>\n",
       "      <td>121</td>\n",
       "      <td>4.304348</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>wish could find unsalted</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>last refrig longtiime</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>13</td>\n",
       "      <td>59</td>\n",
       "      <td>3.615385</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>friend recommended</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bought sams club trying friends houseshe said ...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>189</td>\n",
       "      <td>964</td>\n",
       "      <td>4.105820</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.258333</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>first time ive high omega3 content course gras...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>63</td>\n",
       "      <td>326</td>\n",
       "      <td>4.190476</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046481</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bought lark amazon pleasantly surprised mild s...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>114</td>\n",
       "      <td>626</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.204762</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>longer buy state live wisconsin dairy state do...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>113</td>\n",
       "      <td>544</td>\n",
       "      <td>3.823009</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.105328</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>excellent compares anchor new zealand maybe ev...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>95</td>\n",
       "      <td>525</td>\n",
       "      <td>4.536842</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.469481</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>simply delicious salty bland perfect quite bit...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>39</td>\n",
       "      <td>202</td>\n",
       "      <td>4.205128</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>everything right shipped right away cold ready...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>30</td>\n",
       "      <td>145</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.074286</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>outstanding seller outstanding product came ru...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>51</td>\n",
       "      <td>293</td>\n",
       "      <td>4.764706</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tasting came extreme box ice pack insulated pa...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>43</td>\n",
       "      <td>220</td>\n",
       "      <td>4.139535</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.177885</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>grass feed thing dont finishes quickly larger tub</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>31</td>\n",
       "      <td>148</td>\n",
       "      <td>3.806452</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>huge fan cook spreading bread crackers toast w...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>70</td>\n",
       "      <td>360</td>\n",
       "      <td>4.157143</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.136111</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>kerry gold wish could afford get often</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>18</td>\n",
       "      <td>89</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>arrived packed cold put fridge days spot freez...</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>27</td>\n",
       "      <td>128</td>\n",
       "      <td>3.777778</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>smooth buttery</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>best far using keto way eating</td>\n",
       "      <td>Irish</td>\n",
       "      <td>Butter</td>\n",
       "      <td>12</td>\n",
       "      <td>55</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>liquid</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>tasted fake horrible</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>first time bought canned buy</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>19</td>\n",
       "      <td>97</td>\n",
       "      <td>4.157895</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>smooth works recipes also put back winter nice...</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>30</td>\n",
       "      <td>158</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>soft easy spread</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>wife</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td></td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>product expensive expecting lot flavor</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>15</td>\n",
       "      <td>80</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>expected</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tastes made</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>rich cant stop putting cookies</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>11</td>\n",
       "      <td>55</td>\n",
       "      <td>4.090909</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>tasting bit expensive side amount surely make ...</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>20</td>\n",
       "      <td>107</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>mom buy dutch came round yellow cow design fro...</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>50</td>\n",
       "      <td>240</td>\n",
       "      <td>3.820000</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.261111</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>product comes clear using toast omelet dish fl...</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>28</td>\n",
       "      <td>150</td>\n",
       "      <td>4.392857</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>loved ability keep preserved</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>11</td>\n",
       "      <td>60</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>simply better</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>making cookies produced addition end dutch</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>14</td>\n",
       "      <td>80</td>\n",
       "      <td>4.785714</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td></td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>first time bought canned buy</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>19</td>\n",
       "      <td>97</td>\n",
       "      <td>4.157895</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>smooth works recipes also put back winter nice...</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Butter</td>\n",
       "      <td>30</td>\n",
       "      <td>158</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Review  Brand Category  \\\n",
       "0   didnt get flavor expecting especially price wa...  Irish   Butter   \n",
       "1   dairy ireland umbrella marketing brandname man...  Irish   Butter   \n",
       "2   excellent eating terrible baking makes cookies...  Irish   Butter   \n",
       "3   purchased 8 oz local kroger 399 also purchased...  Irish   Butter   \n",
       "4       im picky dairy save money cheaper even better  Irish   Butter   \n",
       "5                                  drastically priced  Irish   Butter   \n",
       "6                                    dont know pricey  Irish   Butter   \n",
       "7   ive read 90 grass fed finished soy corn women ...  Irish   Butter   \n",
       "8                          creamy smooth texture nice  Irish   Butter   \n",
       "9   tastes creamer get buying dealer found costco ...  Irish   Butter   \n",
       "10                                             really  Irish   Butter   \n",
       "11  thought buying tub easily spread although flav...  Irish   Butter   \n",
       "12                           wish could find unsalted  Irish   Butter   \n",
       "13                              last refrig longtiime  Irish   Butter   \n",
       "14                                 friend recommended  Irish   Butter   \n",
       "15  bought sams club trying friends houseshe said ...  Irish   Butter   \n",
       "16  first time ive high omega3 content course gras...  Irish   Butter   \n",
       "17  bought lark amazon pleasantly surprised mild s...  Irish   Butter   \n",
       "18  longer buy state live wisconsin dairy state do...  Irish   Butter   \n",
       "19  excellent compares anchor new zealand maybe ev...  Irish   Butter   \n",
       "20  simply delicious salty bland perfect quite bit...  Irish   Butter   \n",
       "21  everything right shipped right away cold ready...  Irish   Butter   \n",
       "22  outstanding seller outstanding product came ru...  Irish   Butter   \n",
       "23  tasting came extreme box ice pack insulated pa...  Irish   Butter   \n",
       "24  grass feed thing dont finishes quickly larger tub  Irish   Butter   \n",
       "25  huge fan cook spreading bread crackers toast w...  Irish   Butter   \n",
       "26             kerry gold wish could afford get often  Irish   Butter   \n",
       "27  arrived packed cold put fridge days spot freez...  Irish   Butter   \n",
       "28                                     smooth buttery  Irish   Butter   \n",
       "29                     best far using keto way eating  Irish   Butter   \n",
       "30                                             liquid  Dutch   Butter   \n",
       "31                               tasted fake horrible  Dutch   Butter   \n",
       "32                       first time bought canned buy  Dutch   Butter   \n",
       "33  smooth works recipes also put back winter nice...  Dutch   Butter   \n",
       "34                                   soft easy spread  Dutch   Butter   \n",
       "35                                               wife  Dutch   Butter   \n",
       "36                                                     Dutch   Butter   \n",
       "37             product expensive expecting lot flavor  Dutch   Butter   \n",
       "38                                           expected  Dutch   Butter   \n",
       "39                                        tastes made  Dutch   Butter   \n",
       "40                     rich cant stop putting cookies  Dutch   Butter   \n",
       "41  tasting bit expensive side amount surely make ...  Dutch   Butter   \n",
       "42  mom buy dutch came round yellow cow design fro...  Dutch   Butter   \n",
       "43  product comes clear using toast omelet dish fl...  Dutch   Butter   \n",
       "44                       loved ability keep preserved  Dutch   Butter   \n",
       "45                                      simply better  Dutch   Butter   \n",
       "46         making cookies produced addition end dutch  Dutch   Butter   \n",
       "47                                                     Dutch   Butter   \n",
       "48                       first time bought canned buy  Dutch   Butter   \n",
       "49  smooth works recipes also put back winter nice...  Dutch   Butter   \n",
       "\n",
       "    word_count  char_count  avg_word  stopwords  hastags  numerics  upper  \\\n",
       "0           19          97  4.157895          7        0         0      3   \n",
       "1           75         419  4.600000         30        0         0      1   \n",
       "2           34         181  4.352941         14        0         0      1   \n",
       "3           38         199  4.263158         12        0         1      2   \n",
       "4           24         115  3.833333         12        0         0      1   \n",
       "5            3          23  7.000000          1        0         0      0   \n",
       "6           11          54  4.000000          6        0         0      1   \n",
       "7           38         218  4.763158         13        0         0      0   \n",
       "8            6          38  5.500000          0        0         0      0   \n",
       "9           24         130  4.458333         11        0         0      0   \n",
       "10           3          18  5.333333          0        0         0      0   \n",
       "11          23         121  4.304348          8        0         0      2   \n",
       "12           5          30  5.200000          0        0         0      1   \n",
       "13          13          59  3.615385          6        0         0      0   \n",
       "14           9          53  5.000000          4        0         0      0   \n",
       "15         189         964  4.105820         86        0         0      8   \n",
       "16          63         326  4.190476         29        0         0      1   \n",
       "17         114         626  4.500000         48        0         0      7   \n",
       "18         113         544  3.823009         49        0         1      7   \n",
       "19          95         525  4.536842         38        0         0      1   \n",
       "20          39         202  4.205128         15        0         0      3   \n",
       "21          30         145  3.866667          2        0         0     26   \n",
       "22          51         293  4.764706         20        0         0      0   \n",
       "23          43         220  4.139535         14        0         0      3   \n",
       "24          31         148  3.806452         13        0         0      2   \n",
       "25          70         360  4.157143         27        0         0      3   \n",
       "26          18          89  4.000000          6        0         0      1   \n",
       "27          27         128  3.777778         13        0         0      1   \n",
       "28           4          26  5.750000          0        0         0      0   \n",
       "29          12          55  3.666667          5        0         0      1   \n",
       "30           1           6  6.000000          0        0         0      0   \n",
       "31           4          24  5.250000          1        0         0      0   \n",
       "32          19          97  4.157895          6        0         0      2   \n",
       "33          30         158  4.300000         11        0         0      0   \n",
       "34           5          23  3.800000          2        0         0      0   \n",
       "35           4          15  3.000000          1        0         0      0   \n",
       "36           2          12  5.500000          0        0         0      0   \n",
       "37          15          80  4.400000          6        0         0      1   \n",
       "38           3          17  5.000000          1        0         0      0   \n",
       "39           8          37  3.750000          3        0         0      0   \n",
       "40          11          55  4.090909          5        0         0      0   \n",
       "41          20         107  4.400000          8        0         0      1   \n",
       "42          50         240  3.820000         24        0         0      1   \n",
       "43          28         150  4.392857         13        0         0      0   \n",
       "44          11          60  4.545455          4        0         0      0   \n",
       "45           3          19  5.666667          0        0         0      0   \n",
       "46          14          80  4.785714          5        0         0      0   \n",
       "47           2           7  3.000000          1        0         0      0   \n",
       "48          19          97  4.157895          6        0         0      2   \n",
       "49          30         158  4.300000         11        0         0      0   \n",
       "\n",
       "    sentiment Polarity_Rating  \n",
       "0    0.100000        Positive  \n",
       "1    0.045000        Positive  \n",
       "2    0.100000        Positive  \n",
       "3   -0.037143        Negative  \n",
       "4    0.500000        Positive  \n",
       "5    0.000000         Neutral  \n",
       "6    0.000000         Neutral  \n",
       "7   -0.312500        Negative  \n",
       "8    0.500000        Positive  \n",
       "9    0.000000         Neutral  \n",
       "10   0.200000        Positive  \n",
       "11   0.433333        Positive  \n",
       "12   0.400000        Positive  \n",
       "13   0.000000         Neutral  \n",
       "14   0.000000         Neutral  \n",
       "15   0.258333        Positive  \n",
       "16   0.046481        Positive  \n",
       "17   0.204762        Positive  \n",
       "18   0.105328        Positive  \n",
       "19   0.469481        Positive  \n",
       "20   0.708333        Positive  \n",
       "21   0.074286        Positive  \n",
       "22   0.350000        Positive  \n",
       "23  -0.177885        Negative  \n",
       "24   0.000000         Neutral  \n",
       "25   0.136111        Positive  \n",
       "26   0.000000         Neutral  \n",
       "27  -0.600000        Negative  \n",
       "28   0.400000        Positive  \n",
       "29   0.550000        Positive  \n",
       "30   0.000000         Neutral  \n",
       "31  -0.750000        Negative  \n",
       "32   0.250000        Positive  \n",
       "33   0.250000        Positive  \n",
       "34   0.266667        Positive  \n",
       "35   0.000000         Neutral  \n",
       "36   0.000000         Neutral  \n",
       "37  -0.500000        Negative  \n",
       "38  -0.100000        Negative  \n",
       "39   0.000000         Neutral  \n",
       "40   0.375000        Positive  \n",
       "41   0.333333        Positive  \n",
       "42   0.261111        Positive  \n",
       "43   0.483333        Positive  \n",
       "44   0.700000        Positive  \n",
       "45   0.500000        Positive  \n",
       "46   0.000000         Neutral  \n",
       "47   0.000000         Neutral  \n",
       "48   0.250000        Positive  \n",
       "49   0.250000        Positive  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Polarity_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>didnt get flavor expecting especially price wa...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dairy ireland umbrella marketing brandname man...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>excellent eating terrible baking makes cookies...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>purchased 8 oz local kroger 399 also purchased...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im picky dairy save money cheaper even better</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Polarity_Rating\n",
       "0  didnt get flavor expecting especially price wa...        Positive\n",
       "1  dairy ireland umbrella marketing brandname man...        Positive\n",
       "2  excellent eating terrible baking makes cookies...        Positive\n",
       "3  purchased 8 oz local kroger 399 also purchased...        Negative\n",
       "4      im picky dairy save money cheaper even better        Positive"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train= train[['Review', 'Polarity_Rating']]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wanted to apply One hot encoding on negative, neutral, and positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kftsu\\AppData\\Local\\Temp\\ipykernel_25032\\1597170316.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train.drop(['Polarity_Rating'],axis=1,inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>didnt get flavor expecting especially price wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dairy ireland umbrella marketing brandname man...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>excellent eating terrible baking makes cookies...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>purchased 8 oz local kroger 399 also purchased...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im picky dairy save money cheaper even better</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Negative  Neutral  \\\n",
       "0  didnt get flavor expecting especially price wa...         0        0   \n",
       "1  dairy ireland umbrella marketing brandname man...         0        0   \n",
       "2  excellent eating terrible baking makes cookies...         0        0   \n",
       "3  purchased 8 oz local kroger 399 also purchased...         1        0   \n",
       "4      im picky dairy save money cheaper even better         0        0   \n",
       "\n",
       "   Positive  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         0  \n",
       "4         1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = pd.get_dummies(train[\"Polarity_Rating\"])\n",
    "train.drop(['Polarity_Rating'],axis=1,inplace=True)\n",
    "train = pd.concat([train,one_hot],axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train['Review'].values\n",
    "y = train.drop('Review', axis=1).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "X_train = vect.fit_transform(X_train)\n",
    "X_test = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying frequency, inverse document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer()\n",
    "X_train = tfidf.fit_transform(X_train)\n",
    "X_test = tfidf.transform(X_test)\n",
    "X_train = X_train.toarray()\n",
    "X_test = X_test.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding different layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=12673,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=4000,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=500,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "opt=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.0991 - accuracy: 0.3143 - val_loss: 0.9094 - val_accuracy: 0.6000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.9141 - accuracy: 0.6000 - val_loss: 0.9050 - val_accuracy: 0.6000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 310ms/step - loss: 0.8143 - accuracy: 0.6000 - val_loss: 0.9105 - val_accuracy: 0.6000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.7243 - accuracy: 0.6000 - val_loss: 0.8329 - val_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 346ms/step - loss: 0.5480 - accuracy: 0.6000 - val_loss: 0.7847 - val_accuracy: 0.7333\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 348ms/step - loss: 0.4243 - accuracy: 0.9429 - val_loss: 0.7267 - val_accuracy: 0.8000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.3056 - accuracy: 1.0000 - val_loss: 0.7601 - val_accuracy: 0.8000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.1989 - accuracy: 1.0000 - val_loss: 0.8796 - val_accuracy: 0.8000\n",
      "Epoch 8: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x252492dbc70>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, batch_size=256, epochs=100, validation_data=(X_test, y_test), verbose=1, callbacks=early_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step - loss: 0.8796 - accuracy: 0.8000\n",
      "Test accuracy: 0.800000011920929\n"
     ]
    }
   ],
   "source": [
    "model_score = model.evaluate(X_test, y_test, batch_size=64, verbose=1)\n",
    "print('Test accuracy:', model_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 79ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.19039038e-01, 4.71324563e-01, 3.09636444e-01],\n",
       "       [9.76911187e-02, 5.76400459e-01, 3.25908363e-01],\n",
       "       [2.19039038e-01, 4.71324563e-01, 3.09636444e-01],\n",
       "       [3.86585146e-02, 6.48557246e-02, 8.96485746e-01],\n",
       "       [1.80606835e-03, 1.52789173e-03, 9.96666014e-01],\n",
       "       [9.07197129e-03, 9.65929218e-03, 9.81268704e-01],\n",
       "       [3.70832682e-02, 8.24466199e-02, 8.80470157e-01],\n",
       "       [6.53605210e-03, 6.78230682e-03, 9.86681581e-01],\n",
       "       [9.07197129e-03, 9.65929218e-03, 9.81268704e-01],\n",
       "       [1.30116090e-03, 8.54282989e-04, 9.97844577e-01],\n",
       "       [2.45349333e-02, 2.97011379e-02, 9.45763886e-01],\n",
       "       [1.55700576e-02, 2.31736731e-02, 9.61256325e-01],\n",
       "       [1.13350805e-02, 7.64023559e-03, 9.81024742e-01],\n",
       "       [3.05694179e-03, 3.13306623e-03, 9.93809998e-01],\n",
       "       [2.03211587e-02, 1.92775391e-02, 9.60401297e-01]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(X_test)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 3)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
